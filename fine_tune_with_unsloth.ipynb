{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8261784-a6d2-4491-995f-324884c5b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04640baa-c112-40b7-bfa5-49805e2301a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d12a81-9ce8-4317-9267-ffc0555aed77",
   "metadata": {},
   "source": [
    "## Merge method_change table into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3006900-05aa-4a68-85bc-84e8c8f97952",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/test_pickles_bak/df.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "    df = df.dropna()\n",
    "    df = df[(df['token_count'] < 12000)]\n",
    "    # df = df[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2371b3c8-fa2f-4c80-b5db-8799d85995a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_change_id</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>cwe_id</th>\n",
       "      <th>cwe_name</th>\n",
       "      <th>non_vuln_code</th>\n",
       "      <th>vuln_code</th>\n",
       "      <th>cwe_description</th>\n",
       "      <th>cve_description</th>\n",
       "      <th>token_count</th>\n",
       "      <th>diff_added</th>\n",
       "      <th>diff_deleted</th>\n",
       "      <th>vuln_code_num_lines</th>\n",
       "      <th>non_vuln_code_num_lines</th>\n",
       "      <th>class</th>\n",
       "      <th>method_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41461181100456</td>\n",
       "      <td>C</td>\n",
       "      <td>CWE-252</td>\n",
       "      <td>Unchecked Return Value</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>The product does not check the return value fr...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'manual/search.texi i...</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>[(152,   const char *const start = name;), (15...</td>\n",
       "      <td>[(158,       /* $ORIGIN is not expanded for SU...</td>\n",
       "      <td>1449</td>\n",
       "      <td>1467</td>\n",
       "      <td>CWE-754</td>\n",
       "      <td>_dl_dst_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41461181100456</td>\n",
       "      <td>C</td>\n",
       "      <td>CWE-252</td>\n",
       "      <td>Unchecked Return Value</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>The product does not check the return value fr...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'manual/search.texi i...</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>[(152,   const char *const start = name;), (15...</td>\n",
       "      <td>[(158,       /* $ORIGIN is not expanded for SU...</td>\n",
       "      <td>1449</td>\n",
       "      <td>1467</td>\n",
       "      <td>CWE-754</td>\n",
       "      <td>expand_dynamic_string_token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41461181100456</td>\n",
       "      <td>C</td>\n",
       "      <td>CWE-252</td>\n",
       "      <td>Unchecked Return Value</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>The product does not check the return value fr...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'manual/search.texi i...</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>[(152,   const char *const start = name;), (15...</td>\n",
       "      <td>[(158,       /* $ORIGIN is not expanded for SU...</td>\n",
       "      <td>1449</td>\n",
       "      <td>1467</td>\n",
       "      <td>CWE-754</td>\n",
       "      <td>_dl_dst_substitute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41461181100456</td>\n",
       "      <td>C</td>\n",
       "      <td>CWE-252</td>\n",
       "      <td>Unchecked Return Value</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>The product does not check the return value fr...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'manual/search.texi i...</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>[(152,   const char *const start = name;), (15...</td>\n",
       "      <td>[(158,       /* $ORIGIN is not expanded for SU...</td>\n",
       "      <td>1449</td>\n",
       "      <td>1467</td>\n",
       "      <td>CWE-754</td>\n",
       "      <td>_dl_dst_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41461181100456</td>\n",
       "      <td>C</td>\n",
       "      <td>CWE-252</td>\n",
       "      <td>Unchecked Return Value</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>/* Map in a shared object's segments from the ...</td>\n",
       "      <td>The product does not check the return value fr...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'manual/search.texi i...</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>[(152,   const char *const start = name;), (15...</td>\n",
       "      <td>[(158,       /* $ORIGIN is not expanded for SU...</td>\n",
       "      <td>1449</td>\n",
       "      <td>1467</td>\n",
       "      <td>CWE-754</td>\n",
       "      <td>expand_dynamic_string_token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193645</th>\n",
       "      <td>233098165980480</td>\n",
       "      <td>Python</td>\n",
       "      <td>CWE-79</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>from flask import blueprints, request, jsonify...</td>\n",
       "      <td>from flask import blueprints, request, jsonify...</td>\n",
       "      <td>The product does not neutralize or incorrectly...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'A stored Cross-Site ...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>[(2, from werkzeug.utils import secure_filenam...</td>\n",
       "      <td>[(21,     manager.create_project(project_name)...</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>CWE-74</td>\n",
       "      <td>create_project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193646</th>\n",
       "      <td>168198219170456</td>\n",
       "      <td>Python</td>\n",
       "      <td>CWE-73</td>\n",
       "      <td>External Control of File Name or Path</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>The product allows user input to control or in...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'A local file read vu...</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>[(177, )]</td>\n",
       "      <td>[(177, ), (178,     def get_project_files(self...</td>\n",
       "      <td>201</td>\n",
       "      <td>177</td>\n",
       "      <td>CWE-20</td>\n",
       "      <td>get_project_files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193647</th>\n",
       "      <td>168198219170456</td>\n",
       "      <td>Python</td>\n",
       "      <td>CWE-22</td>\n",
       "      <td>Improper Limitation of a Pathname to a Restric...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>The product uses external input to construct a...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'A directory traversa...</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>[(177, )]</td>\n",
       "      <td>[(177, ), (178,     def get_project_files(self...</td>\n",
       "      <td>201</td>\n",
       "      <td>177</td>\n",
       "      <td>CWE-668</td>\n",
       "      <td>get_project_files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193648</th>\n",
       "      <td>168198219170456</td>\n",
       "      <td>Python</td>\n",
       "      <td>CWE-346</td>\n",
       "      <td>Origin Validation Error</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>The product does not properly verify that the ...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'A CORS misconfigurat...</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>[(177, )]</td>\n",
       "      <td>[(177, ), (178,     def get_project_files(self...</td>\n",
       "      <td>201</td>\n",
       "      <td>177</td>\n",
       "      <td>CWE-346</td>\n",
       "      <td>get_project_files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193649</th>\n",
       "      <td>168198219170456</td>\n",
       "      <td>Python</td>\n",
       "      <td>CWE-79</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>import json\\nimport os\\nfrom datetime import d...</td>\n",
       "      <td>The product does not neutralize or incorrectly...</td>\n",
       "      <td>[{'lang': 'en', 'value': 'A stored Cross-Site ...</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>[(177, )]</td>\n",
       "      <td>[(177, ), (178,     def get_project_files(self...</td>\n",
       "      <td>201</td>\n",
       "      <td>177</td>\n",
       "      <td>CWE-74</td>\n",
       "      <td>get_project_files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46871 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_change_id programming_language   cwe_id   \n",
       "0        41461181100456                    C  CWE-252  \\\n",
       "1        41461181100456                    C  CWE-252   \n",
       "2        41461181100456                    C  CWE-252   \n",
       "3        41461181100456                    C  CWE-252   \n",
       "4        41461181100456                    C  CWE-252   \n",
       "...                 ...                  ...      ...   \n",
       "193645  233098165980480               Python   CWE-79   \n",
       "193646  168198219170456               Python   CWE-73   \n",
       "193647  168198219170456               Python   CWE-22   \n",
       "193648  168198219170456               Python  CWE-346   \n",
       "193649  168198219170456               Python   CWE-79   \n",
       "\n",
       "                                                 cwe_name   \n",
       "0                                  Unchecked Return Value  \\\n",
       "1                                  Unchecked Return Value   \n",
       "2                                  Unchecked Return Value   \n",
       "3                                  Unchecked Return Value   \n",
       "4                                  Unchecked Return Value   \n",
       "...                                                   ...   \n",
       "193645  Improper Neutralization of Input During Web Pa...   \n",
       "193646              External Control of File Name or Path   \n",
       "193647  Improper Limitation of a Pathname to a Restric...   \n",
       "193648                            Origin Validation Error   \n",
       "193649  Improper Neutralization of Input During Web Pa...   \n",
       "\n",
       "                                            non_vuln_code   \n",
       "0       /* Map in a shared object's segments from the ...  \\\n",
       "1       /* Map in a shared object's segments from the ...   \n",
       "2       /* Map in a shared object's segments from the ...   \n",
       "3       /* Map in a shared object's segments from the ...   \n",
       "4       /* Map in a shared object's segments from the ...   \n",
       "...                                                   ...   \n",
       "193645  from flask import blueprints, request, jsonify...   \n",
       "193646  import json\\nimport os\\nfrom datetime import d...   \n",
       "193647  import json\\nimport os\\nfrom datetime import d...   \n",
       "193648  import json\\nimport os\\nfrom datetime import d...   \n",
       "193649  import json\\nimport os\\nfrom datetime import d...   \n",
       "\n",
       "                                                vuln_code   \n",
       "0       /* Map in a shared object's segments from the ...  \\\n",
       "1       /* Map in a shared object's segments from the ...   \n",
       "2       /* Map in a shared object's segments from the ...   \n",
       "3       /* Map in a shared object's segments from the ...   \n",
       "4       /* Map in a shared object's segments from the ...   \n",
       "...                                                   ...   \n",
       "193645  from flask import blueprints, request, jsonify...   \n",
       "193646  import json\\nimport os\\nfrom datetime import d...   \n",
       "193647  import json\\nimport os\\nfrom datetime import d...   \n",
       "193648  import json\\nimport os\\nfrom datetime import d...   \n",
       "193649  import json\\nimport os\\nfrom datetime import d...   \n",
       "\n",
       "                                          cwe_description   \n",
       "0       The product does not check the return value fr...  \\\n",
       "1       The product does not check the return value fr...   \n",
       "2       The product does not check the return value fr...   \n",
       "3       The product does not check the return value fr...   \n",
       "4       The product does not check the return value fr...   \n",
       "...                                                   ...   \n",
       "193645  The product does not neutralize or incorrectly...   \n",
       "193646  The product allows user input to control or in...   \n",
       "193647  The product uses external input to construct a...   \n",
       "193648  The product does not properly verify that the ...   \n",
       "193649  The product does not neutralize or incorrectly...   \n",
       "\n",
       "                                          cve_description  token_count   \n",
       "0       [{'lang': 'en', 'value': 'manual/search.texi i...       6592.0  \\\n",
       "1       [{'lang': 'en', 'value': 'manual/search.texi i...       6592.0   \n",
       "2       [{'lang': 'en', 'value': 'manual/search.texi i...       6592.0   \n",
       "3       [{'lang': 'en', 'value': 'manual/search.texi i...       6592.0   \n",
       "4       [{'lang': 'en', 'value': 'manual/search.texi i...       6592.0   \n",
       "...                                                   ...          ...   \n",
       "193645  [{'lang': 'en', 'value': 'A stored Cross-Site ...        371.0   \n",
       "193646  [{'lang': 'en', 'value': 'A local file read vu...       1284.0   \n",
       "193647  [{'lang': 'en', 'value': 'A directory traversa...       1284.0   \n",
       "193648  [{'lang': 'en', 'value': 'A CORS misconfigurat...       1284.0   \n",
       "193649  [{'lang': 'en', 'value': 'A stored Cross-Site ...       1284.0   \n",
       "\n",
       "                                               diff_added   \n",
       "0       [(152,   const char *const start = name;), (15...  \\\n",
       "1       [(152,   const char *const start = name;), (15...   \n",
       "2       [(152,   const char *const start = name;), (15...   \n",
       "3       [(152,   const char *const start = name;), (15...   \n",
       "4       [(152,   const char *const start = name;), (15...   \n",
       "...                                                   ...   \n",
       "193645  [(2, from werkzeug.utils import secure_filenam...   \n",
       "193646                                          [(177, )]   \n",
       "193647                                          [(177, )]   \n",
       "193648                                          [(177, )]   \n",
       "193649                                          [(177, )]   \n",
       "\n",
       "                                             diff_deleted   \n",
       "0       [(158,       /* $ORIGIN is not expanded for SU...  \\\n",
       "1       [(158,       /* $ORIGIN is not expanded for SU...   \n",
       "2       [(158,       /* $ORIGIN is not expanded for SU...   \n",
       "3       [(158,       /* $ORIGIN is not expanded for SU...   \n",
       "4       [(158,       /* $ORIGIN is not expanded for SU...   \n",
       "...                                                   ...   \n",
       "193645  [(21,     manager.create_project(project_name)...   \n",
       "193646  [(177, ), (178,     def get_project_files(self...   \n",
       "193647  [(177, ), (178,     def get_project_files(self...   \n",
       "193648  [(177, ), (178,     def get_project_files(self...   \n",
       "193649  [(177, ), (178,     def get_project_files(self...   \n",
       "\n",
       "        vuln_code_num_lines  non_vuln_code_num_lines    class   \n",
       "0                      1449                     1467  CWE-754  \\\n",
       "1                      1449                     1467  CWE-754   \n",
       "2                      1449                     1467  CWE-754   \n",
       "3                      1449                     1467  CWE-754   \n",
       "4                      1449                     1467  CWE-754   \n",
       "...                     ...                      ...      ...   \n",
       "193645                   54                       63   CWE-74   \n",
       "193646                  201                      177   CWE-20   \n",
       "193647                  201                      177  CWE-668   \n",
       "193648                  201                      177  CWE-346   \n",
       "193649                  201                      177   CWE-74   \n",
       "\n",
       "                        method_name  \n",
       "0                     _dl_dst_count  \n",
       "1       expand_dynamic_string_token  \n",
       "2                _dl_dst_substitute  \n",
       "3                     _dl_dst_count  \n",
       "4       expand_dynamic_string_token  \n",
       "...                             ...  \n",
       "193645               create_project  \n",
       "193646            get_project_files  \n",
       "193647            get_project_files  \n",
       "193648            get_project_files  \n",
       "193649            get_project_files  \n",
       "\n",
       "[46871 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59afaf40-5499-455b-8da4-5c92fc05de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cve_description(cve_list):\n",
    "    if not cve_list:\n",
    "        return \"No CVE description available.\"\n",
    "    \n",
    "    for cve in cve_list:\n",
    "        if cve.get(\"lang\") == \"en\":\n",
    "            return cve.get(\"value\", \"No CVE description available.\")\n",
    "    \n",
    "    return cve_list[0].get(\"value\", \"No CVE description available.\")\n",
    "\n",
    "def format_diff_deleted(diff_deleted):\n",
    "    if not diff_deleted:\n",
    "        return \"No specific deleted lines available.\"\n",
    "    return \"\\n\".join([f\"{line[1]}\" for line in diff_deleted])\n",
    "\n",
    "def generate_prompts(df, output_file=\"prompts.txt\"):\n",
    "    prompts = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "### Instruction:\n",
    "You are a security expert tasked with identifying vulnerabilities in a given code. Carefully analyze the code using CWE (Common Weakness Enumeration) descriptions and determine if it contains any vulnerabilities step by step.\n",
    "\n",
    "### Input:\n",
    "Here is a code snippet that may contain a security vulnerability:\n",
    "\n",
    "{row['vuln_code']}\n",
    "\n",
    "\n",
    "### Response:\n",
    "Name of function or method that could be exploited: {row['method_name']}\n",
    "The part of the code that could be exploited: \n",
    "{format_diff_deleted(row['diff_deleted'])}\n",
    "\n",
    "The identified vulnerability corresponds to {row['cwe_id']}, which is known as \"{row['cwe_name']}.\" This type of vulnerability is described as follows: {row['cwe_description']}\n",
    "\n",
    "The reason this code is classified under {row['cwe_id']} is that {extract_cve_description(row['cve_description'])}\n",
    "        \"\"\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "prompts = generate_prompts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a6d5f-1f00-462e-993b-59c679dfa083",
   "metadata": {},
   "source": [
    "## Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2480321d-7466-4544-bd3f-86940dddf70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: GRID A100-10C. Max memory: 9.996 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 18000  # 任意の値を選択可能。RoPEスケーリングは内部で自動的にサポート\n",
    "dtype = torch.bfloat16  # 自動検出の場合はNone。Tesla T4、V100の場合はFloat16、Ampere以降の場合はBfloat16\n",
    "load_in_4bit = True  # メモリ使用量を削減するために4ビット量子化を使用。Falseも可能\n",
    "\n",
    "# 4倍高速なダウンロードとOOMの回避のためにサポートされている4ビット事前量子化モデル\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",  # 新しいMistral v3は2倍高速\n",
    "    \"unsloth/codellama-7b-bnb-4bit\",\n",
    "    \"unsloth/phi-4-bnb-4bit\",  # Llama-3 15兆トークンモデルは2倍高速\n",
    "    \"unsloth/DeepSeek-R1-Distill-Qwen-14B-bnb-4bit\",\n",
    "]  # その他のモデルについては、https://huggingface.co/unsloth をご覧ください\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=fourbit_models[0],\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    # token=\"hf_...\",  # meta-llama/Llama-2-7b-hfのようなゲート付きモデルを使用する場合は、これを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453e65da-810d-4d6a-9991-85bcdb6c85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"], \n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29b4c9a-57d1-463a-b564-c4b4a4d5154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(prompts):\n",
    "    return { \"text\": [prompt + EOS_TOKEN for prompt in prompts] }\n",
    "\n",
    "# Format the dataset\n",
    "formatted_data = formatting_prompts_func(prompts)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_dict(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ceb602-f392-41db-8f6d-ec0d0c197d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51c4e14d9f24989841cf23642e698b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML (num_proc=4):   0%|          | 0/46871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1c13a5f8dc4795b9eff111649d8c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset (num_proc=4):   0%|          | 0/46871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a581705b384d7a85dfe5f3211ccbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=4):   0%|          | 0/46871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8111c888c5c8472992cabac494ff538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=4):   0%|          | 0/46871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=4,\n",
    "    packing=False,  # 短いシーケンスの場合、トレーニングを5倍高速化できます\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        warmup_steps=5,\n",
    "        max_steps=60,\n",
    "        # num_train_epochs = 1,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_torch\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=1234,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522e91f2-e5d0-4e2b-8874-a659f0c4ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 46,871 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/60 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacity of 10.00 GiB of which 306.50 MiB is free. Including non-PyTorch memory, this process has 8.80 GiB memory in use. Of the allocated memory 7.96 GiB is allocated by PyTorch, and 351.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:329\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:73\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py:2329\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2329\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:307\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:511\u001b[0m, in \u001b[0;36mcustom_bwd.<locals>.decorate_bwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(bwd)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_bwd\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(\n\u001b[1;32m    507\u001b[0m         device_type\u001b[38;5;241m=\u001b[39mdevice_type,\n\u001b[1;32m    508\u001b[0m         enabled\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast,\n\u001b[1;32m    509\u001b[0m         dtype\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m    510\u001b[0m     ):\n\u001b[0;32m--> 511\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth_zoo/gradient_checkpointing.py:161\u001b[0m, in \u001b[0;36mUnsloth_Offloaded_Gradient_Checkpointer.backward\u001b[0;34m(ctx, dY)\u001b[0m\n\u001b[1;32m    159\u001b[0m hidden_states\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 161\u001b[0m     (output,) \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(output, dY)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, hidden_states\u001b[38;5;241m.\u001b[39mgrad,) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m,)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(ctx\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/models/llama.py:548\u001b[0m, in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    547\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm, hidden_states)\n\u001b[0;32m--> 548\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/kernels/fast_lora.py:162\u001b[0m, in \u001b[0;36mapply_lora_mlp_swiglu\u001b[0;34m(self, X, inplace)\u001b[0m\n\u001b[1;32m    160\u001b[0m upW,     upW_quant,   upA,   upB,   upS \u001b[38;5;241m=\u001b[39m get_lora_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m  up_proj)\n\u001b[1;32m    161\u001b[0m downW, downW_quant, downA, downB, downS \u001b[38;5;241m=\u001b[39m get_lora_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj)\n\u001b[0;32m--> 162\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mLoRA_MLP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgateW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mupW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[43mupW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdownW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mswiglu_fg_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswiglu_DWf_DW_dfg_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                     \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:465\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/kernels/fast_lora.py:76\u001b[0m, in \u001b[0;36mLoRA_MLP.forward\u001b[0;34m(ctx, X, gateW, gateW_quant, gateA, gateB, gateS, upW, upW_quant, upA, upB, upS, downW, downW_quant, downA, downB, downS, _forward_function, _backward_function, inplace)\u001b[0m\n\u001b[1;32m     73\u001b[0m dtype \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     75\u001b[0m e \u001b[38;5;241m=\u001b[39m matmul_lora(X, gateW, gateW_quant, gateA, gateB, gateS)\n\u001b[0;32m---> 76\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mmatmul_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m h \u001b[38;5;241m=\u001b[39m _forward_function(e, g)\n\u001b[1;32m     78\u001b[0m i \u001b[38;5;241m=\u001b[39m matmul_lora(h, downW, downW_quant, downA, downB, downS)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/kernels/utils.py:464\u001b[0m, in \u001b[0;36mmatmul_lora\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# LoRA is enabled\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     A, B \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mt(), B\u001b[38;5;241m.\u001b[39mt()\n\u001b[0;32m--> 464\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mview(batch, seq_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m reshape \u001b[38;5;28;01melse\u001b[39;00m out\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacity of 10.00 GiB of which 306.50 MiB is free. Including non-PyTorch memory, this process has 8.80 GiB memory in use. Of the allocated memory 7.96 GiB is allocated by PyTorch, and 351.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f41c4-3945-403b-be59-e580fb41123b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
